# World of Books Discovery Platform - Backend

Production-grade NestJS backend with real data scraping from worldofbooks.com.

## Architecture

```
backend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scraper/           # Crawlee + Playwright scraping engine
â”‚   â”‚   â”œâ”€â”€ real-scraper.ts       # Core scraper implementation
â”‚   â”‚   â””â”€â”€ scraper.service.ts    # NestJS service wrapper
â”‚   â”œâ”€â”€ database/          # MongoDB configuration
â”‚   â”œâ”€â”€ navigation/        # Navigation endpoints & logic
â”‚   â”œâ”€â”€ categories/        # Categories endpoints & logic
â”‚   â”œâ”€â”€ products/          # Products endpoints & logic
â”‚   â”œâ”€â”€ search/            # Full-text search functionality
â”‚   â”œâ”€â”€ history/           # View history tracking
â”‚   â”œâ”€â”€ schemas/           # MongoDB schemas
â”‚   â”œâ”€â”€ cli/               # CLI scripts for scraping
â”‚   â”œâ”€â”€ app.module.ts      # Main app module
â”‚   â””â”€â”€ main.ts            # Application entry point
```

## Key Features

### ğŸ•·ï¸ Real-Time Web Scraping

- **Crawlee + Playwright** for JavaScript-heavy site scraping
- **Headless browser** automation with Playwright
- **Smart selectors** adapted for worldofbooks.com structure
- **Error handling** with fallbacks and retries

### ğŸ—„ï¸ MongoDB Storage

Collections:
- `navigation` - Top-level navigation headings
- `category` - Categories and subcategories
- `product` - Book listings with metadata
- `product_detail` - Detailed product information
- `review` - Product reviews (extensible)
- `scrape_job` - Job tracking for scraping operations
- `view_history` - User browsing history

Indexes:
- Full-text search on `product.title` and `product.author`
- Unique constraints on `source_id` + `source_url`
- TTL indexes for automatic data cleanup

### âš¡ Caching Strategy

- **In-memory caching** via `CACHE_TTL_SECONDS` (default: 24 hours)
- **Background refresh** - Stale data is served while new data is fetched
- **No blocking requests** - All scraping operations are asynchronous
- **Exponential backoff** for failed scrapes

### ğŸ“¡ RESTful APIs

#### Navigation
```
GET /api/navigation
  - Get all navigation headings from cache
  - Automatic background refresh if stale

GET /api/navigation/:slug
  - Get categories for a navigation section
  
POST /api/navigation/refresh
  - Force refresh of navigation data
```

#### Products
```
GET /api/products?category=fiction&page=1&limit=24&search=&sort=newest
  - Paginated product listing
  - Category filtering
  - Full-text search
  - Sorting: newest, price-asc, price-desc, rating

GET /api/products/:id
  - Detailed product view
  - Related reviews

POST /api/products/:id/refresh
  - Refresh specific product data
```

#### Search
```
GET /api/search?query=term&limit=20
  - Full-text search with fallback regex

GET /api/search/autocomplete?query=term
  - Autocomplete suggestions

GET /api/search/filters
  - Available filter options (price range, ratings, etc.)
```

#### History
```
POST /api/history
  - Record product view
  
GET /api/history?user_id=&limit=20
  - Get browsing history
  
GET /api/history/popular
  - Get popular products by view count
  
GET /api/history/analytics
  - Analytics dashboard data
```

### ğŸ“Š Database Indexes

Optimized for:
- Fast category lookups by slug
- Full-text search on titles and authors
- Efficient pagination
- Quick historical data retrieval

## Setup

### Prerequisites

- Node.js 18+
- MongoDB 5.0+
- Docker (optional)

### Local Development

1. **Install dependencies**
   ```bash
   cd backend
   npm install
   ```

2. **Configure environment**
   ```bash
   cp .env.example .env
   # Edit .env with your MongoDB connection
   ```

3. **Start MongoDB**
   ```bash
   # Using Docker
   docker run -d -p 27017:27017 --name mongodb mongo:5.0
   
   # Or use your local MongoDB installation
   ```

4. **Start backend**
   ```bash
   npm run start:dev
   
   # Server will be available at http://localhost:3001
   # API docs: http://localhost:3001/api/docs
   ```

## Validation Scripts

### Scrape Fiction Books (Real Data Test)

```bash
npm run scrape:fiction
```

This script:
1. âœ… Connects to worldofbooks.com via Playwright
2. âœ… Scrapes real navigation headings
3. âœ… Finds fiction category
4. âœ… Extracts book listings
5. âœ… Scrapes product details
6. âœ… Logs first book details

Expected output:
```
ğŸš€ Starting Fiction Books Scraper Validation
ğŸ“ STEP 1: Scraping navigation headings...
âœ… Navigation scraped: 3 items found
  1. Books (books)
  2. New Arrivals (new-arrivals)
  3. Bestsellers (bestsellers)

ğŸ“ STEP 2: Locating fiction books category...
âœ… Found: Books (https://www.worldofbooks.com/en-gb/books)

ğŸ“ STEP 3: Scraping categories from fiction...
âœ… Categories scraped: 15+ items found

ğŸ“ STEP 4: Scraping products from category...
âœ… Products scraped: 20+ items found

ğŸ“ STEP 5: First product details:
  ğŸ“– Title: [Real Book Title]
  âœï¸  Author: [Real Author Name]
  ğŸ’° Price: Â£[Real Price]
  ğŸ“¸ Image: Yes
  ğŸ”— URL: https://www.worldofbooks.com/en-gb/books/[product-id]

âœ… ==========================================
âœ… VALIDATION SUCCESSFUL!
âœ… Real data scraped from: https://www.worldofbooks.com
```

## Scraping Strategy

### How It Works

1. **Request arrives** for navigation/products/details
2. **Check MongoDB cache** for existing data
3. **If cache fresh** (<24 hours): Return immediately
4. **If cache stale**: 
   - Return cached data immediately
   - Trigger background scrape
   - Update database when complete
5. **If no cache**: Scrape immediately, store result

### Handled Scenarios

- JavaScript-rendered content (Playwright)
- Dynamic pagination
- Image lazy-loading
- Rate limiting (waits between requests)
- Connection failures (exponential backoff)
- Partial data (graceful degradation)

### Data Quality

- âœ… Real data from worldofbooks.com
- âœ… Deduplication by `source_url`
- âœ… Sanitized input validation
- âœ… Consistent data types
- âœ… UTC timestamps

## Production Deployment

### Docker

```bash
# Build image
docker build -t wob-backend .

# Run container
docker run -p 3001:3001 \
  -e MONGODB_URI=mongodb://mongodb:27017/world_of_books \
  -e CORS_ORIGIN=https://yourdomain.com \
  wob-backend
```

### Environment Variables

All configurable via `.env`:
- `MONGODB_URI` - MongoDB connection string
- `MONGODB_DB_NAME` - Database name
- `API_PORT` - Server port (default: 3001)
- `CORS_ORIGIN` - Allowed frontend URLs
- `CACHE_TTL_SECONDS` - Cache expiration (default: 86400)
- `LOG_LEVEL` - Logging verbosity (debug, info, warn, error)

### Monitoring

- Swagger API docs: `GET /api/docs`
- Health check: `GET /api/health` (add endpoint if needed)
- Logs: Configure `LOG_LEVEL` for detailed output

## Testing

```bash
# Run tests
npm test

# Watch mode
npm run test:watch

# Coverage
npm run test:cov
```

## Development

### Building

```bash
npm run build
npm start
```

### Debugging

```bash
npm run start:debug
# Then connect debugger to port 9229
```

## API Documentation

Complete Swagger documentation available at:
```
http://localhost:3001/api/docs
```

Generated from JSDoc/Swagger decorators in controllers.

## Error Handling

All endpoints return standardized JSON errors:

```json
{
  "statusCode": 400,
  "message": "Detailed error message",
  "error": "BadRequest"
}
```

## Rate Limiting (Optional)

Can be added via:
```typescript
@UseGuards(ThrottlerGuard)
@Throttle(100, 900) // 100 requests per 15 minutes
```

## Security

- âœ… Input validation with class-validator
- âœ… CORS configured per environment
- âœ… Helmet for security headers
- âœ… .env secrets not committed
- âœ… No SQL injection (MongoDB)
- âœ… XSS protection in responses

## License

MIT
